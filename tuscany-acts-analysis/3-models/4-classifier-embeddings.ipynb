{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import activations\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "# to make the experimens replicable\n",
    "random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "\n",
    "as first step run the notebook `1. classification-dataset-creation.ipynb` to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/dataset-dirigenti-split.pkl'\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    train_samples, train_labels, val_samples, val_labels, test_samples, test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform it in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'RESIDUI PERENTI BILANCIO 1997 - IMPEGNO E LIQUIDAZIONE ALL ORDINE PROVINCIALE DEI MEDICI-CHIRURGHI E DEGLI ODONTOIATRI DI FIRENZE PERL ATTUAZIONE DI INIZIATIVE CULTURALI E SCIENTIFICHE DI SUPPORTO AI CORSI DI FORMAZIONE SPECIFICA IN MEDICINA GENERALE.',\n",
       "       'L.R. 72/94 \" Danni causati da animali predatori o da eventi meteorici al patrimonio zootecnico\" - Liquidazione indennizzi beneficiari Euro 34.988,28=.',\n",
       "       'Eventi alluvionali novembre 2000 - Interventi urgenti connessi alla difesa idraulica - Erogazione al Comune di Montemurlo (PO) saldo finanziamento spettante per realizzazione intervento n. 301 compreso nel Piano regionale di cui all`allegato 2 della DGRT n. 104/2003.',\n",
       "       'APPROVAZIONE SCHEMA DI CONVENZIONE TRA LA REGIONE TOSCANA E I SOGGETTI PRIVATI AMMESSI A CONTRIBUTO PER I PROGETTI-INTERVENTO IN MATERIA DI PAESAGGIO',\n",
       "       'Contributo al Comune di Siena per l`organizzazione della Terza giornata del Contemporaneo in programma nel mese di ottobre 2007.'],\n",
       "      dtype='<U961')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01943', '01934',\n",
       "       'DIREZIONE GENERALE POLITICHE TERRITORIALI E AMBIENTALI',\n",
       "       'DIREZIONE GENERALE POLITICHE TERRITORIALI E AMBIENTALI',\n",
       "       'DIREZIONE GENERALE POLITICHE FORMATIVE, BENI E ATTIVIT'],\n",
       "      dtype='<U54')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138043,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.concatenate([train_samples,val_samples, test_samples])\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138043,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.concatenate([train_labels, val_labels, test_labels])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = [(v,k) for k,v in tokenizer.word_docs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(108923, 'di'),\n",
       " (70047, 'e'),\n",
       " (62030, 'del'),\n",
       " (60358, 'per'),\n",
       " (48081, 'r'),\n",
       " (46824, 'l'),\n",
       " (44301, 'n'),\n",
       " (43630, 'a'),\n",
       " (40125, 'della'),\n",
       " (32549, 'in')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(freq_words, key=lambda t: t[0], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_samples)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_samples)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1120, 915, 418, 721, 14, 2, 18, 50, 2055, 530, 21, 1072, 2, 52, 1, 66, 179, 1, 691, 749, 2, 5399, 1, 512, 25, 723, 1, 129, 1100, 10, 558, 321]\n",
      "[7, 6, 956, 88, 740, 2101, 45, 1187, 3733, 132, 45, 277, 4270, 13, 313, 1613, 18, 2539, 965, 221, 708, 7629, 298]\n"
     ]
    }
   ],
   "source": [
    "for s in train_sequences[:2]:\n",
    "    print(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_labels = dict(enumerate(set(labels)))\n",
    "labels_to_index = {v:k for k,v in index_to_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D.G.  AVVOCATURA                                      ': 0, 'DIREZIONE GENERALE POLITICHE FORMATIVE, BENI E ATTIVIT': 1, 'DIREZIONE GENERALE POLITICHE TERRITORIALI E AMBIENTALI': 2, '01946': 3, '01934': 4, 'DIREZIONE ISTRUZIONE E FORMAZIONE': 5, \"D.G. COMPETITIVITA' DEL SISTEMA REGIONALE E SVILUPPO D\": 6, 'POLITICHE AMBIENTALI, ENERGIA E CAMBIAMENTI CLIMATICI': 7, 'DIREZIONE GENERALE DIRITTO ALLA SALUTE E POLITICHE DI ': 8, '01937': 9, 'DIREZIONE ORGANIZZAZIONE E SISTEMI INFORMATIVI': 10, '01928': 11, 'DIREZIONE GENERALE SVILUPPO ECONOMICO                 ': 12, 'DIREZIONE AGRICOLTURA E SVILUPPO RURALE': 13, 'DIREZIONE DIFESA DEL SUOLO E PROTEZIONE CIVILE': 14, 'DIREZIONE GENERALE BILANCIO E FINANZE                 ': 15, 'DIREZIONE DIRITTI DI CITTADINANZA E COESIONE SOCIALE': 16, '01025': 17, 'D.G. PRESIDENZA                                       ': 18, '01943': 19}\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(labels_to_index)\n",
    "print(len(labels_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_labels = [labels_to_index[l] for l in train_labels]\n",
    "encoded_val_labels = [labels_to_index[l] for l in val_labels]\n",
    "encoded_test_labels = [labels_to_index[l] for l in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 4, 2, 2, 1, 0, 10, 5, 15, 6]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data\n",
    "\n",
    "- for the input data we pad the sequence to a max length in order to make uniform the sequences.\n",
    "- for the labels we continue with one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of objects 150\n"
     ]
    }
   ],
   "source": [
    "print('max length of objects {}'.format(max(map(len, train_sequences))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Sequence Length\n",
    "\n",
    "for initial test we use the first 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = sequence.pad_sequences(train_sequences, maxlen=maxlen)\n",
    "x_val_seq = sequence.pad_sequences(val_sequences, maxlen=maxlen)\n",
    "x_test_seq = sequence.pad_sequences(test_sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99390, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    data = np.zeros((len(sequences), dimension), dtype=np.float32)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        data[i,sequence] = 1.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_sequences, num_words)\n",
    "x_val = vectorize_sequences(val_sequences, num_words)\n",
    "x_test = vectorize_sequences(test_sequences, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels):\n",
    "    results = np.zeros((len(labels), len(set(labels))), dtype=np.float32)\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_one_hot(encoded_train_labels)\n",
    "y_val = to_one_hot(encoded_val_labels)\n",
    "y_test = to_one_hot(encoded_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Effects of Word Embeddings\n",
    "\n",
    "Before using a word embedding as a layer in our network let evaluate the effect of embeddings by training a simple classifier that has it as only layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_only_embeddings(embed_size):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=num_words, output_dim=embed_size, input_length=maxlen, name='embed'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(len(labels_to_index), activation='softmax', name='softmax'))\n",
    "    model.compile(optimizer=optimizers.Adam(), \n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_only_embed_small = build_model_only_embeddings(32)\n",
    "model_only_embed_medium = build_model_only_embeddings(64)\n",
    "model_only_embed_large = build_model_only_embeddings(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_embed_small = model_only_embed_small.fit(x=x_train_seq, y=y_train, validation_data=(x_val_seq, y_val),\n",
    "                   epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_embed_medium = model_only_embed_medium.fit(x=x_train_seq, y=y_train, validation_data=(x_val_seq, y_val),\n",
    "                   epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_embed_large = model_only_embed_large.fit(x=x_train_seq, y=y_train, validation_data=(x_val_seq, y_val),\n",
    "                   epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_loss(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'b+', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yticks(np.arange(0,2.2, step=0.2))\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_acc(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'b+', label='Training Acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuray')\n",
    "    plt.yticks(np.arange(0.4,1.05, step=0.05))\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_loss(history_embed_small)\n",
    "chart_loss(history_embed_medium)\n",
    "chart_loss(history_embed_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the model with larger embedding size tend to overfit faster than the others (respectively epochs 2, 3, and 4). However, from a loss point of view all the models starts overfitting with a loss values ~ 0.8.\n",
    "Let's now analyze values for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_acc(history_embed_small)\n",
    "chart_acc(history_embed_medium)\n",
    "chart_acc(history_embed_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_loss(history):\n",
    "    val_loss = history.history['val_loss'] \n",
    "    return np.argmin(val_loss) + 1 \n",
    "\n",
    "def accuracy(history, epoch):\n",
    "    val_acc = history.history['val_acc']\n",
    "    return val_acc[epoch - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min loss for model small is {}'.format(min_loss(history_embed_small)))\n",
    "print('min loss for model medium is {}'.format(min_loss(history_embed_medium)))\n",
    "print('min loss for model large is {}'.format(min_loss(history_embed_large)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best validation accuracy for model small is {}'.format(\n",
    "    accuracy(history_embed_small, min_loss(history_embed_small))))\n",
    "print('best validation accuracy for model medium is {}'.format(\n",
    "    accuracy(history_embed_medium, min_loss(history_embed_medium))))\n",
    "print('best validation accuracy for model large is {}'.format(\n",
    "    accuracy(history_embed_large, min_loss(history_embed_large))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show how only using an flat classifier with an embedding layer we obtain an accuracy ~ 83%. Which is a pretty good result.\n",
    "The next steps is use an embedding layers in a Feed Forward Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Models\n",
    "\n",
    "We take into account:\n",
    "- a base model that uses dropout\n",
    "- a embed model that adds an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_dropout(neurons):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(neurons, activation='relu', input_shape=(x_train.shape[-1], )))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(neurons, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(neurons, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(len(labels_to_index), activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_embeddings(neurons, embed_size):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=num_words, output_dim=embed_size, input_length=maxlen))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(neurons, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(neurons, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(len(labels_to_index), activation='softmax'))\n",
    "    model.compile(optimizer=optimizers.Adam(), \n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = build_model_dropout(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = model_dropout.fit(x=x_train, y=y_train, validation_data=(x_val, y_val),\n",
    "                   epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embed = build_model_embeddings(128,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_embed = model_embed.fit(x=x_train_seq, y=y_train, validation_data=(x_val_seq, y_val),\n",
    "                   epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing The Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_loss(history_embed)\n",
    "chart_loss(history_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the charts we can see that: \n",
    "- word embedding seems to not improve the accuracy of the model. This is usual in the case you have little training data available. From another point of view it is surprising to see that the classifier with only an embedding layer perform better than the one taken into account here\n",
    "- the model with dropout perform better than the model with embeddings.\n",
    "\n",
    "From this result one could gather that embeddings are not useful. This is wrong, because we didn't consider that we changed another thing with the current represantion. The model that uses embedding takes as input sequence of ids and not a vectorize representation of subjects. \n",
    "\n",
    "In the next post we will explore the usage of LSTM to address this kind of representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_acc(history_embed)\n",
    "chart_acc(history_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chart above we can see that the best model is the model that uses dropout, while the best epoch is the 6 where the validation accuracy crosses the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_loss(histories):\n",
    "    epochs = range(1, len(list(histories.values())[0].history['val_loss']) + 1)\n",
    "\n",
    "    for i, history in histories.items():\n",
    "        val_loss = history.history['val_loss']\n",
    "        plt.plot(epochs, val_loss, label='Validation Loss {}'.format(i))\n",
    "            \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_loss({'embedding': history_embed, 'Dropout': history_dropout})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting factor is that the loss of the model that uses embeddings grows during the training. It shows that embedding trained with the model aren't useful.\n",
    "Another approach can be uses:\n",
    "- pretrained embeddings\n",
    "- remove some of the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_accuracy(histories):\n",
    "    epochs = range(1, len(list(histories.values())[0].history['val_acc']) + 1)\n",
    "\n",
    "    for i, history in histories.items():\n",
    "        val_loss = history.history['val_acc']\n",
    "        plt.plot(epochs, val_loss, label='Validation Accuracy {}'.format(i))\n",
    "            \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracy({'embedding': history_embed, 'Dropout': history_dropout})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min loss for model Embed {}'.format(min_loss(history_embed)))\n",
    "print('min loss for model Dropout is {}'.format(min_loss(history_dropout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best validation accuracy for model Embed {}'.format(\n",
    "    accuracy(history_embed, min_loss(history_embed))))\n",
    "print('best validation accuracy for model Dropout {}'.format(\n",
    "    accuracy(history_dropout, min_loss(history_dropout))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the Test Set\n",
    "\n",
    "We still want to evaluate the models with embedding to understand if it overfits on input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_embeddings(128,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=np.concatenate([x_train_seq, x_val_seq]), y=np.concatenate([y_train, y_val]), epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loss {}'.format(loss))\n",
    "print('acc {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We evaluated how to use Embeddings as alternative to one-hot encoding. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
