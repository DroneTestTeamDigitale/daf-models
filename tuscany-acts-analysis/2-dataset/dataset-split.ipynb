{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# to make the experimens replicable\n",
    "random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/atti-dirigenti-processed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "\n",
    "for the analysis we are going to create a dataset where the `OGGETTO` is the independent variable while the `UFFICIO_DG` is the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152455, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df[['OGGETTO', 'UFFICIO_DG', 'DATA_ATTO']]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups the documents by office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OGGETTO</th>\n",
       "      <th>DATA_ATTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4234.861111</td>\n",
       "      <td>4234.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4010.579446</td>\n",
       "      <td>4010.579446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1011.250000</td>\n",
       "      <td>1011.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2870.000000</td>\n",
       "      <td>2870.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7239.750000</td>\n",
       "      <td>7239.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13826.000000</td>\n",
       "      <td>13826.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OGGETTO     DATA_ATTO\n",
       "count     36.000000     36.000000\n",
       "mean    4234.861111   4234.861111\n",
       "std     4010.579446   4010.579446\n",
       "min      105.000000    105.000000\n",
       "25%     1011.250000   1011.250000\n",
       "50%     2870.000000   2870.000000\n",
       "75%     7239.750000   7239.750000\n",
       "max    13826.000000  13826.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_per_office = dataset.groupby(['UFFICIO_DG']).count()\n",
    "documents_per_office.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset Creation\n",
    "\n",
    "Here, we can:\n",
    "- select the documents with frequency greater that the 25 percentile\n",
    "- or use all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = 2000\n",
    "sel_dataset = documents_per_office[documents_per_office.OGGETTO >= 2000]\n",
    "sel_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/miniconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sel_dataset['UFFICIO_DG'] = sel_dataset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OGGETTO</th>\n",
       "      <th>DATA_ATTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6902.150000</td>\n",
       "      <td>6902.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3539.235857</td>\n",
       "      <td>3539.235857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2624.000000</td>\n",
       "      <td>2624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3719.250000</td>\n",
       "      <td>3719.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6590.500000</td>\n",
       "      <td>6590.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9389.500000</td>\n",
       "      <td>9389.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13826.000000</td>\n",
       "      <td>13826.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OGGETTO     DATA_ATTO\n",
       "count     20.000000     20.000000\n",
       "mean    6902.150000   6902.150000\n",
       "std     3539.235857   3539.235857\n",
       "min     2624.000000   2624.000000\n",
       "25%     3719.250000   3719.250000\n",
       "50%     6590.500000   6590.500000\n",
       "75%     9389.500000   9389.500000\n",
       "max    13826.000000  13826.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OGGETTO</th>\n",
       "      <th>DATA_ATTO</th>\n",
       "      <th>UFFICIO_DG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UFFICIO_DG</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01025</th>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>01025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01928</th>\n",
       "      <td>2710</td>\n",
       "      <td>2710</td>\n",
       "      <td>01928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01934</th>\n",
       "      <td>4923</td>\n",
       "      <td>4923</td>\n",
       "      <td>01934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01937</th>\n",
       "      <td>7160</td>\n",
       "      <td>7160</td>\n",
       "      <td>01937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01943</th>\n",
       "      <td>3833</td>\n",
       "      <td>3833</td>\n",
       "      <td>01943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OGGETTO  DATA_ATTO UFFICIO_DG\n",
       "UFFICIO_DG                               \n",
       "01025          3030       3030      01025\n",
       "01928          2710       2710      01928\n",
       "01934          4923       4923      01934\n",
       "01937          7160       7160      01937\n",
       "01943          3833       3833      01943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the dataset to select a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds = dataset.merge(sel_dataset, how='inner', on=['UFFICIO_DG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138043, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the OGGETTO and UFFICIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OGGETTO_x</th>\n",
       "      <th>UFFICIO_DG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGR 968/07 e s.m.i. Accreditamento degli organ...</td>\n",
       "      <td>DIREZIONE ISTRUZIONE E FORMAZIONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nomina Commissione d’esame per il percorso for...</td>\n",
       "      <td>DIREZIONE ISTRUZIONE E FORMAZIONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nomina della Commissione d'esame matricola 201...</td>\n",
       "      <td>DIREZIONE ISTRUZIONE E FORMAZIONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Progetti formativi per drop-out a.s.f. 2015-20...</td>\n",
       "      <td>DIREZIONE ISTRUZIONE E FORMAZIONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REG (CE) 1080/2006-Por Creo Fesr 2007-2013-Lin...</td>\n",
       "      <td>DIREZIONE ISTRUZIONE E FORMAZIONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           OGGETTO_x  \\\n",
       "0  DGR 968/07 e s.m.i. Accreditamento degli organ...   \n",
       "1  Nomina Commissione d’esame per il percorso for...   \n",
       "2  Nomina della Commissione d'esame matricola 201...   \n",
       "3  Progetti formativi per drop-out a.s.f. 2015-20...   \n",
       "4  REG (CE) 1080/2006-Por Creo Fesr 2007-2013-Lin...   \n",
       "\n",
       "                          UFFICIO_DG  \n",
       "0  DIREZIONE ISTRUZIONE E FORMAZIONE  \n",
       "1  DIREZIONE ISTRUZIONE E FORMAZIONE  \n",
       "2  DIREZIONE ISTRUZIONE E FORMAZIONE  \n",
       "3  DIREZIONE ISTRUZIONE E FORMAZIONE  \n",
       "4  DIREZIONE ISTRUZIONE E FORMAZIONE  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ds = final_ds[['OGGETTO_x',\"UFFICIO_DG\"]]\n",
    "final_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(final_ds['UFFICIO_DG']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform it in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, label in final_ds.as_matrix():\n",
    "    samples.append(text)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"DGR 968/07 e s.m.i. Accreditamento degli organismi formativi. Rilascio dell'accreditamento all'organismo formativo Bioscience Research Center - cod. GR1035.\",\n",
       " 'Nomina Commissione d’esame per il percorso formativo “Formazione obbligatoria per utilizzatori professionali di prodotti fitosanitari”, MATRICOLA N. 2016SI0046',\n",
       " \"Nomina della Commissione d'esame matricola 2016PI0301. Agenzia Formativa Cescot\",\n",
       " 'Progetti formativi per drop-out a.s.f. 2015-2016. Integrazione impegno per progetto \"Figaro - Operatore del benessere (acconciatura)\"',\n",
       " 'REG (CE) 1080/2006-Por Creo Fesr 2007-2013-Linea di intevento 5.1.d-Chiusura attività']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIREZIONE ISTRUZIONE E FORMAZIONE',\n",
       " 'DIREZIONE ISTRUZIONE E FORMAZIONE',\n",
       " 'DIREZIONE ISTRUZIONE E FORMAZIONE',\n",
       " 'DIREZIONE ISTRUZIONE E FORMAZIONE',\n",
       " 'DIREZIONE ISTRUZIONE E FORMAZIONE']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/dataset-dirigenti.pkl', 'wb') as o:\n",
    "    pickle.dump((samples, labels), o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/dataset-dirigenti.pkl'\n",
    "\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    samples, labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Set\n",
    "\n",
    "- shuffle data\n",
    "- split the dataset into 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test = StratifiedShuffleSplit(1,test_size=0.2, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in split_train_test.split(samples, labels):\n",
    "    train_split_samples, test_split_samples = samples[train], samples[test]\n",
    "    train_split_labels, test_split_labels = labels[train], labels[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a label index vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label_dict = dict(enumerate(set(train_split_labels),0))\n",
    "label_index_dict = {v:k for k,v in index_label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01943': 0,\n",
       " 'DIREZIONE GENERALE SVILUPPO ECONOMICO                 ': 1,\n",
       " '01946': 2,\n",
       " '01025': 3,\n",
       " 'D.G. PRESIDENZA                                       ': 4,\n",
       " '01934': 5,\n",
       " 'DIREZIONE GENERALE DIRITTO ALLA SALUTE E POLITICHE DI ': 6,\n",
       " 'DIREZIONE GENERALE POLITICHE TERRITORIALI E AMBIENTALI': 7,\n",
       " '01937': 8,\n",
       " 'D.G.  AVVOCATURA                                      ': 9,\n",
       " '01928': 10,\n",
       " 'POLITICHE AMBIENTALI, ENERGIA E CAMBIAMENTI CLIMATICI': 11,\n",
       " 'DIREZIONE ORGANIZZAZIONE E SISTEMI INFORMATIVI': 12,\n",
       " 'DIREZIONE GENERALE BILANCIO E FINANZE                 ': 13,\n",
       " 'DIREZIONE DIFESA DEL SUOLO E PROTEZIONE CIVILE': 14,\n",
       " 'DIREZIONE GENERALE POLITICHE FORMATIVE, BENI E ATTIVIT': 15,\n",
       " \"D.G. COMPETITIVITA' DEL SISTEMA REGIONALE E SVILUPPO D\": 16,\n",
       " 'DIREZIONE DIRITTI DI CITTADINANZA E COESIONE SOCIALE': 17,\n",
       " 'DIREZIONE ISTRUZIONE E FORMAZIONE': 18,\n",
       " 'DIREZIONE AGRICOLTURA E SVILUPPO RURALE': 19}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dirigenti_label_index.json', 'w') as f: \n",
    "    json.dump(label_index_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Train and Test Labels to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([label_index_dict[l] for l in train_split_labels])\n",
    "test_labels = np.array([label_index_dict[l] for l in test_split_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 11  3 ...,  4  4 17]\n",
      "[ 6  7  4 ...,  1  8 16]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word index vocabulary\n",
    "\n",
    "we create the word index with all the tokens from the train sample (with punctuation and stop-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/fabio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/fabio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ['-', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}', '’', '”', '“', '``', \"''\"]\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "stop_words.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sample(samples, remove_stopwords=True, tokenizer=word_tokenize):\n",
    "    for sample in samples:\n",
    "        words = []\n",
    "        sample = sample.replace('`', ' ')\n",
    "        sample = sample.replace(\"'\", \" \")\n",
    "        for w in tokenizer(sample):\n",
    "            if remove_stopwords:\n",
    "                if w not in stop_words:\n",
    "                    words.append(w.lower())\n",
    "            else:\n",
    "                words.append(w.lower())\n",
    "        yield words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_tokenized = tokenize_sample(train_split_samples, remove_stopwords=False, tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in train_samples_tokenized:\n",
    "    counter.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 256844),\n",
       " ('di', 181082),\n",
       " ('-', 86613),\n",
       " ('e', 82411),\n",
       " ('del', 73939),\n",
       " ('per', 63553),\n",
       " (',', 57757),\n",
       " ('n.', 40423),\n",
       " ('della', 39756),\n",
       " (')', 34981),\n",
       " ('``', 32901),\n",
       " ('a', 32144),\n",
       " ('(', 31821),\n",
       " (\"''\", 31650),\n",
       " ('in', 30318),\n",
       " ('dell', 25572),\n",
       " ('la', 23388),\n",
       " ('al', 21711),\n",
       " ('impegno', 20898),\n",
       " ('regionale', 20120)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the word_index_dict and the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_dict = dict(enumerate([ k for k,v in counter.most_common()],3))\n",
    "word_index_dict = {v:k for k,v in index_word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dirigenti_word_index.json', 'w') as f: \n",
    "    json.dump(word_index_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dirigenti_most_common.json', 'w') as f:\n",
    "    json.dump(counter.most_common(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the samples from words to sequnce of index\n",
    "\n",
    "we reserve some index for utility chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_char = 0\n",
    "start_char=1\n",
    "oov_char=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_tokenized = tokenize_sample(train_split_samples, remove_stopwords=False, tokenizer=word_tokenize)\n",
    "test_samples_tokenized = tokenize_sample(test_split_samples, remove_stopwords=False, tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_idx(tokenized_samples, word_index_dict):\n",
    "    for sample in tokenized_samples:\n",
    "        encoded_sample = []\n",
    "        for w in sample:\n",
    "            if w in word_index_dict:\n",
    "                encoded_sample.append(word_index_dict[w])\n",
    "            else:\n",
    "                encoded_sample.append(oov_char)\n",
    "        yield encoded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = np.array(list(samples_to_idx(train_samples_tokenized, word_index_dict)))\n",
    "test_data = np.array(list(samples_to_idx(test_samples_tokenized, word_index_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_val = StratifiedShuffleSplit(1,test_size=0.1, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train, val in split_train_val.split(train_sample, train_labels):\n",
    "    train_data, val_data = train_sample[train], train_sample[val]\n",
    "    train_labels_, val_labels = train_labels[train], train_labels[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels training (99390,)\n",
      "labels validation (11044,)\n",
      "labels test (27609,)\n"
     ]
    }
   ],
   "source": [
    "print('labels training {}'.format(train_labels_.shape))\n",
    "print('labels validation {}'.format(val_labels.shape))\n",
    "print('labels test {}'.format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples training (99390,)\n",
      "samples validation (11044,)\n",
      "samples test (27609,)\n"
     ]
    }
   ],
   "source": [
    "print('samples training {}'.format(train_data.shape))\n",
    "print('samples validation {}'.format(val_data.shape))\n",
    "print('samples test {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('data_dirigenti.npz', \n",
    "                    x_train=train_data, y_train=train_labels, \n",
    "                    x_val=val_data, y_val=val_labels, \n",
    "                    x_test=test_data, y_test=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('data_dirigenti.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99390,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded['x_train'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
